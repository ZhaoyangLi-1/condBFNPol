#!/usr/bin/env python3
"""Analyze training efficiency: BFN vs Diffusion.

Generates publication-quality figures comparing:
1. Training loss curves
2. Validation performance over time
3. Sample efficiency (performance vs training steps)
4. Convergence speed analysis
"""

import json
import numpy as np
from pathlib import Path
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from collections import defaultdict
import re

# Style
COLORS = {
    'bfn': '#4285F4',
    'diffusion': '#EA4335',
}

plt.rcParams.update({
    'font.family': 'serif',
    'font.size': 10,
    'axes.titlesize': 11,
    'axes.labelsize': 10,
    'legend.fontsize': 9,
    'figure.dpi': 150,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight',
    'axes.spines.top': False,
    'axes.spines.right': False,
})


def parse_json_logs(log_path):
    """Parse logs.json.txt file."""
    logs = []
    try:
        with open(log_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        logs.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
    except Exception as e:
        print(f"  Warning: Could not parse {log_path}: {e}")
    return logs


def extract_training_data(logs):
    """Extract training metrics from logs."""
    data = {
        'steps': [],
        'epochs': [],
        'train_loss': [],
        'val_loss': [],
        'test_score': [],
    }
    
    for entry in logs:
        if 'global_step' in entry:
            data['steps'].append(entry['global_step'])
        if 'epoch' in entry:
            data['epochs'].append(entry['epoch'])
        if 'train_loss' in entry:
            data['train_loss'].append(entry['train_loss'])
        if 'val_loss' in entry:
            data['val_loss'].append(entry['val_loss'])
        if 'test/mean_score' in entry:
            data['test_score'].append(entry['test/mean_score'])
        elif 'test_mean_score' in entry:
            data['test_score'].append(entry['test_mean_score'])
    
    return data


def find_training_logs(base_dir):
    """Find all training log files."""
    base_path = Path(base_dir)
    
    bfn_logs = []
    diffusion_logs = []
    
    # Search for logs.json.txt files
    for log_file in base_path.rglob('logs.json.txt'):
        path_str = str(log_file)
        
        # Determine if BFN or Diffusion based on path
        if 'bfn' in path_str.lower():
            bfn_logs.append(log_file)
        elif 'diffusion' in path_str.lower():
            diffusion_logs.append(log_file)
    
    return bfn_logs, diffusion_logs


def aggregate_runs(log_files, method_name):
    """Aggregate data across multiple runs."""
    all_data = []
    
    for log_file in log_files:
        print(f"  Parsing: {log_file.parent.name}")
        logs = parse_json_logs(log_file)
        if logs:
            data = extract_training_data(logs)
            if data['train_loss']:
                all_data.append(data)
    
    if not all_data:
        return None
    
    # Find common length (minimum across runs)
    min_len = min(len(d['train_loss']) for d in all_data)
    
    # Aggregate
    aggregated = {
        'steps': all_data[0]['steps'][:min_len] if all_data[0]['steps'] else list(range(min_len)),
        'train_loss_mean': [],
        'train_loss_std': [],
        'test_score_mean': [],
        'test_score_std': [],
    }
    
    # Compute mean and std for each step
    for i in range(min_len):
        losses = [d['train_loss'][i] for d in all_data if i < len(d['train_loss'])]
        if losses:
            aggregated['train_loss_mean'].append(np.mean(losses))
            aggregated['train_loss_std'].append(np.std(losses))
    
    # For test scores (typically per epoch, not per step)
    if all_data[0]['test_score']:
        min_score_len = min(len(d['test_score']) for d in all_data if d['test_score'])
        for i in range(min_score_len):
            scores = [d['test_score'][i] for d in all_data if i < len(d['test_score'])]
            if scores:
                aggregated['test_score_mean'].append(np.mean(scores))
                aggregated['test_score_std'].append(np.std(scores))
    
    return aggregated


def plot_training_curves(bfn_data, diff_data, output_dir):
    """Plot training loss curves."""
    fig, ax = plt.subplots(figsize=(5, 3.5))
    
    # BFN
    if bfn_data and bfn_data['train_loss_mean']:
        steps = range(len(bfn_data['train_loss_mean']))
        mean = np.array(bfn_data['train_loss_mean'])
        std = np.array(bfn_data['train_loss_std'])
        
        ax.plot(steps, mean, color=COLORS['bfn'], linewidth=1.5, label='BFN Policy')
        ax.fill_between(steps, mean - std, mean + std, color=COLORS['bfn'], alpha=0.2)
    
    # Diffusion
    if diff_data and diff_data['train_loss_mean']:
        steps = range(len(diff_data['train_loss_mean']))
        mean = np.array(diff_data['train_loss_mean'])
        std = np.array(diff_data['train_loss_std'])
        
        ax.plot(steps, mean, color=COLORS['diffusion'], linewidth=1.5, label='Diffusion Policy')
        ax.fill_between(steps, mean - std, mean + std, color=COLORS['diffusion'], alpha=0.2)
    
    ax.set_xlabel('Training Steps')
    ax.set_ylabel('Training Loss')
    ax.set_title('Training Convergence', fontweight='bold')
    ax.legend(loc='upper right')
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_yscale('log')
    
    plt.tight_layout()
    fig.savefig(str(Path(output_dir) / 'fig_training_convergence.pdf'), format='pdf')
    fig.savefig(str(Path(output_dir) / 'fig_training_convergence.png'), format='png', dpi=300)
    plt.close(fig)
    print(f"âœ“ Training convergence plot saved")


def plot_performance_over_training(bfn_data, diff_data, output_dir):
    """Plot test performance over training epochs."""
    fig, ax = plt.subplots(figsize=(5, 3.5))
    
    # BFN
    if bfn_data and bfn_data['test_score_mean']:
        epochs = range(len(bfn_data['test_score_mean']))
        mean = np.array(bfn_data['test_score_mean'])
        std = np.array(bfn_data['test_score_std'])
        
        ax.plot(epochs, mean, color=COLORS['bfn'], linewidth=1.5, 
                marker='o', markersize=3, label='BFN Policy')
        ax.fill_between(epochs, mean - std, mean + std, color=COLORS['bfn'], alpha=0.2)
    
    # Diffusion
    if diff_data and diff_data['test_score_mean']:
        epochs = range(len(diff_data['test_score_mean']))
        mean = np.array(diff_data['test_score_mean'])
        std = np.array(diff_data['test_score_std'])
        
        ax.plot(epochs, mean, color=COLORS['diffusion'], linewidth=1.5,
                marker='s', markersize=3, label='Diffusion Policy')
        ax.fill_between(epochs, mean - std, mean + std, color=COLORS['diffusion'], alpha=0.2)
    
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Test Success Score')
    ax.set_title('Sample Efficiency', fontweight='bold')
    ax.legend(loc='lower right')
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_ylim(0, 1.05)
    
    plt.tight_layout()
    fig.savefig(str(Path(output_dir) / 'fig_sample_efficiency.pdf'), format='pdf')
    fig.savefig(str(Path(output_dir) / 'fig_sample_efficiency.png'), format='png', dpi=300)
    plt.close(fig)
    print(f"âœ“ Sample efficiency plot saved")


def plot_combined_training(bfn_data, diff_data, output_dir):
    """Create combined 2-panel training analysis figure."""
    fig, axes = plt.subplots(1, 2, figsize=(9, 3.5))
    
    # Panel A: Training Loss
    ax = axes[0]
    if bfn_data and bfn_data['train_loss_mean']:
        steps = range(len(bfn_data['train_loss_mean']))
        mean = np.array(bfn_data['train_loss_mean'])
        std = np.array(bfn_data['train_loss_std'])
        ax.plot(steps, mean, color=COLORS['bfn'], linewidth=1.5, label='BFN')
        ax.fill_between(steps, mean - std, mean + std, color=COLORS['bfn'], alpha=0.2)
    
    if diff_data and diff_data['train_loss_mean']:
        steps = range(len(diff_data['train_loss_mean']))
        mean = np.array(diff_data['train_loss_mean'])
        std = np.array(diff_data['train_loss_std'])
        ax.plot(steps, mean, color=COLORS['diffusion'], linewidth=1.5, label='Diffusion')
        ax.fill_between(steps, mean - std, mean + std, color=COLORS['diffusion'], alpha=0.2)
    
    ax.set_xlabel('Training Steps')
    ax.set_ylabel('Training Loss')
    ax.set_title('(a) Training Convergence', fontweight='bold')
    ax.legend(loc='upper right', fontsize=8)
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_yscale('log')
    
    # Panel B: Test Performance
    ax = axes[1]
    if bfn_data and bfn_data['test_score_mean']:
        epochs = range(len(bfn_data['test_score_mean']))
        mean = np.array(bfn_data['test_score_mean'])
        std = np.array(bfn_data['test_score_std'])
        ax.plot(epochs, mean, color=COLORS['bfn'], linewidth=1.5, 
                marker='o', markersize=4, label='BFN')
        ax.fill_between(epochs, mean - std, mean + std, color=COLORS['bfn'], alpha=0.2)
    
    if diff_data and diff_data['test_score_mean']:
        epochs = range(len(diff_data['test_score_mean']))
        mean = np.array(diff_data['test_score_mean'])
        std = np.array(diff_data['test_score_std'])
        ax.plot(epochs, mean, color=COLORS['diffusion'], linewidth=1.5,
                marker='s', markersize=4, label='Diffusion')
        ax.fill_between(epochs, mean - std, mean + std, color=COLORS['diffusion'], alpha=0.2)
    
    ax.set_xlabel('Evaluation Epoch')
    ax.set_ylabel('Test Success Score')
    ax.set_title('(b) Learning Progress', fontweight='bold')
    ax.legend(loc='lower right', fontsize=8)
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_ylim(0, 1.05)
    
    plt.tight_layout()
    fig.savefig(str(Path(output_dir) / 'fig_training_analysis.pdf'), format='pdf')
    fig.savefig(str(Path(output_dir) / 'fig_training_analysis.png'), format='png', dpi=300)
    plt.close(fig)
    print(f"âœ“ Combined training analysis figure saved")


def compute_training_statistics(bfn_data, diff_data):
    """Compute key training statistics."""
    stats = {}
    
    if bfn_data and bfn_data['train_loss_mean']:
        stats['bfn'] = {
            'final_loss': bfn_data['train_loss_mean'][-1],
            'final_loss_std': bfn_data['train_loss_std'][-1],
            'min_loss': min(bfn_data['train_loss_mean']),
            'convergence_step': np.argmin(bfn_data['train_loss_mean']),
        }
        if bfn_data['test_score_mean']:
            stats['bfn']['final_score'] = bfn_data['test_score_mean'][-1]
            stats['bfn']['max_score'] = max(bfn_data['test_score_mean'])
            stats['bfn']['epoch_to_90'] = next(
                (i for i, s in enumerate(bfn_data['test_score_mean']) if s >= 0.9), 
                len(bfn_data['test_score_mean'])
            )
    
    if diff_data and diff_data['train_loss_mean']:
        stats['diffusion'] = {
            'final_loss': diff_data['train_loss_mean'][-1],
            'final_loss_std': diff_data['train_loss_std'][-1],
            'min_loss': min(diff_data['train_loss_mean']),
            'convergence_step': np.argmin(diff_data['train_loss_mean']),
        }
        if diff_data['test_score_mean']:
            stats['diffusion']['final_score'] = diff_data['test_score_mean'][-1]
            stats['diffusion']['max_score'] = max(diff_data['test_score_mean'])
            stats['diffusion']['epoch_to_90'] = next(
                (i for i, s in enumerate(diff_data['test_score_mean']) if s >= 0.9),
                len(diff_data['test_score_mean'])
            )
    
    return stats


def generate_training_table(stats, output_dir):
    """Generate LaTeX table for training statistics."""
    table = r"""\begin{table}[t]
\centering
\caption{\textbf{Training Efficiency Comparison.} Both methods show similar 
training dynamics, with comparable convergence speed and final performance.}
\label{tab:training}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{BFN} & \textbf{Diffusion} \\
\midrule
"""
    
    if 'bfn' in stats and 'diffusion' in stats:
        bfn = stats['bfn']
        diff = stats['diffusion']
        
        table += f"Final Training Loss & ${bfn['final_loss']:.4f}$ & ${diff['final_loss']:.4f}$ \\\\\n"
        
        if 'final_score' in bfn and 'final_score' in diff:
            table += f"Final Test Score & ${bfn['final_score']:.3f}$ & ${diff['final_score']:.3f}$ \\\\\n"
            table += f"Peak Test Score & ${bfn['max_score']:.3f}$ & ${diff['max_score']:.3f}$ \\\\\n"
        
        if 'epoch_to_90' in bfn and 'epoch_to_90' in diff:
            table += f"Epochs to 90\\% & {bfn['epoch_to_90']} & {diff['epoch_to_90']} \\\\\n"
    
    table += r"""\bottomrule
\end{tabular}
\end{table}
"""
    
    output_path = Path(output_dir) / 'table_training.tex'
    with open(output_path, 'w') as f:
        f.write(table)
    print(f"âœ“ Training statistics table saved to: {output_path}")


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--log-dir', type=str, default='outputs/2025.12.25',
                        help='Base directory containing training logs')
    parser.add_argument('--output-dir', type=str, default='figures/publication',
                        help='Output directory for figures')
    args = parser.parse_args()
    
    print("=" * 70)
    print("TRAINING EFFICIENCY ANALYSIS")
    print("=" * 70)
    
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Find logs
    print(f"\nSearching for training logs in: {args.log_dir}")
    bfn_logs, diff_logs = find_training_logs(args.log_dir)
    
    print(f"  Found {len(bfn_logs)} BFN training logs")
    print(f"  Found {len(diff_logs)} Diffusion training logs")
    
    if not bfn_logs and not diff_logs:
        print("\nNo training logs found! Checking alternative locations...")
        # Try alternative paths
        for alt_dir in ['outputs', 'runs', 'experiments']:
            if Path(alt_dir).exists():
                bfn_logs, diff_logs = find_training_logs(alt_dir)
                if bfn_logs or diff_logs:
                    print(f"  Found logs in {alt_dir}/")
                    break
    
    # Aggregate data
    print("\nAggregating BFN runs...")
    bfn_data = aggregate_runs(bfn_logs, 'BFN') if bfn_logs else None
    
    print("\nAggregating Diffusion runs...")
    diff_data = aggregate_runs(diff_logs, 'Diffusion') if diff_logs else None
    
    if not bfn_data and not diff_data:
        print("\nERROR: No valid training data found!")
        print("Make sure your training logs contain 'train_loss' and 'test/mean_score' entries.")
        return
    
    # Generate figures
    print("\nGenerating figures...")
    
    if bfn_data or diff_data:
        plot_training_curves(bfn_data, diff_data, args.output_dir)
        plot_performance_over_training(bfn_data, diff_data, args.output_dir)
        plot_combined_training(bfn_data, diff_data, args.output_dir)
    
    # Compute and save statistics
    print("\nComputing training statistics...")
    stats = compute_training_statistics(bfn_data, diff_data)
    
    if stats:
        print("\n" + "-" * 50)
        print("TRAINING STATISTICS")
        print("-" * 50)
        for method, s in stats.items():
            print(f"\n{method.upper()}:")
            for key, val in s.items():
                if isinstance(val, float):
                    print(f"  {key}: {val:.4f}")
                else:
                    print(f"  {key}: {val}")
        
        generate_training_table(stats, 'figures/tables')
    
    print("\n" + "=" * 70)
    print("TRAINING ANALYSIS COMPLETE")
    print("=" * 70)
    print(f"\nGenerated files in {args.output_dir}/:")
    print("  ðŸ“Š fig_training_convergence.pdf")
    print("  ðŸ“Š fig_sample_efficiency.pdf") 
    print("  ðŸ“Š fig_training_analysis.pdf (combined)")
    print("  ðŸ“‹ figures/tables/table_training.tex")


if __name__ == '__main__':
    main()

