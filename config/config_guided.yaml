defaults:
  - _self_

# Global Params
action_dim: 2
obs_dim: 2
chunk_size: 16  # Prediction Horizon

# =============================================================================
# LIGHTNING MODULE (Task)
# =============================================================================
task:
  _target_: tasks.policy_training.PolicyTraining
  _recursive_: false
  
  optimizer:
    _target_: torch.optim.AdamW
    lr: 1.0e-4
    weight_decay: 1.0e-4
  
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 200
    eta_min: 1.0e-6
    interval: epoch
    frequency: 1
  
  policy:
    _target_: policies.guided_bfn_policy.GuidedBFNPolicy
    
    action_space:
      _target_: gymnasium.spaces.Box
      low: -1.0
      high: 1.0
      shape: 
        - ${action_dim}
      dtype: float32
      
    action_dim: ${action_dim}
    
    # 1. Encoders & Normalizers
    normalizer_type: linear
    obs_encoder_type: identity 
    
    # 2. Horizon Configuration
    horizons:
      _target_: policies.guided_bfn_policy.HorizonConfig
      obs_history: 1
      prediction: ${chunk_size}
      execution: 8
    
    # 3. Backbone Configuration (Integrated MLP)
    backbone_config:
      _target_: policies.guided_bfn_policy.BackboneConfig
      hidden_dim: 512
      depth: 4
      time_emb_dim: 128
      conditioning_type: film
      dropout: 0.0
      
    # 4. Guidance Configuration (Flow Matching Params)
    guidance:
      _target_: policies.guided_bfn_policy.GuidanceConfig
      steps: 20
      cfg_scale: 1.0  # 1.0 = Standard conditional generation
      grad_scale: 0.0 # 0.0 = No cost-function guidance during training
    
    device: cpu # Use 'cuda' or 'mps' if available

# =============================================================================
# DATA MODULE
# =============================================================================
datamodule:
  _target_: tasks.point_maze_datamodule.PointMazeDataModule
  n_episodes: 1000
  chunk_size: ${chunk_size}
  batch_size: 512
  max_steps: 200
  seed: 42
  num_workers: 0

# =============================================================================
# TRAINER
# =============================================================================
trainer:
  _target_: lightning.pytorch.Trainer
  accelerator: auto
  devices: 1
  max_epochs: 200
  gradient_clip_val: 1.0
  log_every_n_steps: 10
  enable_checkpointing: true

logging:
  wandb:
    project: mazii-guided
    resume: True
    mode: online
    entity: aleyna-research
    id: null
    group: null