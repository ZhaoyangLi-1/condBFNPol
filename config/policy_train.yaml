defaults:
  - _self_

action_dim: 2
obs_dim: 2
chunk_size: 8  # The magic number for stability

# =============================================================================
# LIGHTNING MODULE (Task)
# =============================================================================
task:
  _target_: tasks.policy_training.PolicyTraining
  # CRITICAL FIX: Prevent Hydra from instantiating optimizer/policy immediately.
  _recursive_: false
  
  # Optimizer (Lower LR for stability)
  optimizer:
    _target_: torch.optim.AdamW
    lr: 1.0e-4
    weight_decay: 1.0e-3

  # Scheduler (Cosine Decay)
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 100
    eta_min: 1.0e-6
    interval: epoch
    frequency: 1

  # Policy
  policy:
    _target_: policies.bfn_policy.BFNPolicy
    
    # --- FIX: Use Block Style for Shape ---
    # Avoids yaml.parser.ParserError by using a list dash instead of brackets []
    action_space:
      _target_: gymnasium.spaces.Box
      low: -1.0
      high: 1.0
      shape: 
        - ${action_dim}
      dtype: float32
    
    # Dimensions
    action_dim: ${action_dim}
    # Chunking: This tells the policy to reshape (B, 16) -> (B, 8, 2)
    n_action_steps: ${chunk_size} 
    
    # BFN Params (Relaxed Sigma)
    config:
      _target_: policies.bfn_policy.BFNConfig
      sigma_1: 0.01
      n_timesteps: 20
      cond_scale: null
      deterministic_seed: 42

    # Network (Deep MLP)
    network:
      _target_: networks.resnet.Resnet
      # IMPORTANT: Network sees Flattened Action Dim (2 * 8 = 16)
      # Hydra doesn't support math in interpolation by default, so we hardcode 16 (2*8)
      dim: 16  
      cond_dim: ${obs_dim}
      hidden_dim: 256
      depth: 3
      time_dim: 128
      dropout: 0.0
    
    # No image encoder needed for PointMaze
    obs_encoder: null
    device: cpu

# =============================================================================
# DATA MODULE
# =============================================================================
datamodule:
  _target_: tasks.point_maze_datamodule.PointMazeDataModule
  n_episodes: 1000
  chunk_size: ${chunk_size}
  batch_size: 512
  max_steps: 200
  seed: 42
  num_workers: 0

# =============================================================================
# TRAINER
# =============================================================================
trainer:
  _target_: lightning.pytorch.Trainer
  accelerator: auto
  devices: 1
  max_epochs: 100
  gradient_clip_val: 2.0
  log_every_n_steps: 10
  enable_checkpointing: true

logging:
  wandb:
    project: mamam
    resume: True
    mode: online
    entity: aleyna-research
    id: null
    group: null

